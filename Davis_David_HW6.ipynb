{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946f6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8adab7",
   "metadata": {},
   "source": [
    "## Questions 1-4\n",
    "\n",
    "In this dataset, match treated (﻿X equals 1﻿) to untreated (﻿X equals 0﻿) based on the confounder (﻿Z﻿). Find the average treatment effect (each item corresponds to one counterfactual) where the counterfactual is the nearest item in the other group (you can use NearestNeighbors for this.) Then, find the average treatment effect on the treated, where each treated item corresponds to a counterfactual untreated item, but we otherwise ignore the untreated items. Then, find the average treatment effect on the untreated, where each untreated item corresponds to a counterfactual treated item, but we otherwise ignore the treated items. Finally, find the marginal treatment effect, which is the maximum treatment effect across all untreated items (i.e., it ends up considering only a single untreated item with its single counterfactual). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01b9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Z</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.548814</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.817325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.423655</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.635482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Z  X         Y\n",
       "0           0  0.548814  0 -0.823220\n",
       "1           1  0.715189  1  0.842405\n",
       "2           2  0.602763  1  0.898618\n",
       "3           3  0.544883  0 -0.817325\n",
       "4           4  0.423655  0 -0.635482"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6_1 = pd.read_csv('homework_6.1.csv')\n",
    "\n",
    "df_6_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02eab517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into treated and untreated groups\n",
    "\n",
    "treated = df_6_1[df_6_1['X'] == 1].reset_index(drop=True)\n",
    "untreated = df_6_1[df_6_1['X'] == 0].reset_index(drop=True)\n",
    "\n",
    "Z_treated = treated[['Z']]\n",
    "Z_untreated = untreated[['Z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386ede4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Nearest Neighbor Models\n",
    "\n",
    "nn_treated = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(Z_untreated)\n",
    "nn_untreated = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(Z_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca518ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect on the Treated (ATT): 1.8464\n"
     ]
    }
   ],
   "source": [
    "#Match Each Treated to Closest Untreated (ATT)\n",
    "dist_tu, idx_tu = nn_treated.kneighbors(Z_treated)\n",
    "Y_untreated_match = untreated.loc[idx_tu.flatten(), 'Y'].values\n",
    "ATT = np.mean(treated['Y'].values - Y_untreated_match)\n",
    "\n",
    "print(f\"Average Treatment Effect on the Treated (ATT): {ATT:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f572db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect on the Untreated (ATU): 1.5495\n"
     ]
    }
   ],
   "source": [
    "#Match Each Untreated to Closest Treated (ATU)\n",
    "dist_ut, idx_ut = nn_untreated.kneighbors(Z_untreated)\n",
    "Y_treated_match = treated.loc[idx_ut.flatten(), 'Y'].values\n",
    "ATU = np.mean(Y_treated_match - untreated['Y'].values)\n",
    "\n",
    "print(f\"Average Treatment Effect on the Untreated (ATU): {ATU:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c116386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (ATE): 1.6953\n"
     ]
    }
   ],
   "source": [
    "# Average Treatment Effect (ATE)\n",
    "\n",
    "ATE = np.mean(np.concatenate([\n",
    "    treated['Y'].values - Y_untreated_match,\n",
    "    Y_treated_match - untreated['Y'].values\n",
    "]))\n",
    "print(f\"Average Treatment Effect (ATE): {ATE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591cd695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal Treatment Effect: 2.1763\n"
     ]
    }
   ],
   "source": [
    "#Marginal Treatment Effect \n",
    "marginal_effects = treated['Y'].values - Y_untreated_match\n",
    "marginal_effect = np.max(marginal_effects)  \n",
    "print(f\"Marginal Treatment Effect: {marginal_effect:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b74b8",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. What is a potential problem with computing the Marginal Treatment Effect simply by comparing each untreated item to its counterfactual and taking the maximum difference?  (Hint: think of statistics here.  Consider that only the most extreme item ends up being used to estimate the MTE.  That's not necessarily a bad thing; the MTE is supposed to come from the untreated item that will produce the maximum effect.  But there is nevertheless a problem.)\n",
    "Possible answer: We are likely to find the item with the most extreme difference, which may be high simply due to randomness.\n",
    "(Please explain / justify this answer, or give a different one if you can think of one.)\n",
    "\n",
    "\n",
    "The Marginal Treatment Effect (MTE) estimates the causal effect for the untreated unit at the margin, where treatment yields the most significant effect. Calculating MTE by comparing each untreated unit to its counterfactual and taking the maximum difference only highlights the most extreme observed difference, which may be due to random noise rather than an actual treatment effect. This overestimates the true maximum because the maximum value often results from sampling variability, known as extreme value or selection bias. For example, rolling 100 dice will likely produce a max of 6, even though the average is 3.5, illustrating bias when focusing on extremes and in MTE, choosing the untreated unit with the most significant observed effect risks confusing noise with real signal, overestimating the effect, and producing unstable estimates that won’t replicate. To address this, modeling the distribution of effects and accounting for variability is necessary, rather than relying solely on the raw maximum. Estimate the actual marginal treatment effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7737373",
   "metadata": {},
   "source": [
    "2. Propose a solution that remedies this problem and write some code that implements your solution.  It's very important here that you clearly explain what your solution will do.\n",
    "Possible answer: maybe we could take the 90th percentile of the treatment effect and use it as a proxy for the Marginal Treatment Effect.\n",
    "(Either code this answer or choose a different one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85db7e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Marginal Treatment Effect (90th percentile): 10.867251482674538\n"
     ]
    }
   ],
   "source": [
    "# Simulate some untreated units\n",
    "np.random.seed(42)  # for reproducibility\n",
    "num_units = 100\n",
    "\n",
    "# Assume untreated outcomes (Y0) and predicted treated outcomes (Y1_hat)\n",
    "Y0 = np.random.normal(loc=50, scale=10, size=num_units)          # observed untreated outcomes\n",
    "Y1_hat = Y0 + np.random.normal(loc=5, scale=5, size=num_units)  # predicted treated outcomes\n",
    "\n",
    "# Compute individual treatment effects (ITE)\n",
    "ITE = Y1_hat - Y0\n",
    "\n",
    "# Compute 90th percentile as a robust proxy for MTE\n",
    "mte_estimate = np.percentile(ITE, 90)\n",
    "\n",
    "print(\"Estimated Marginal Treatment Effect (90th percentile):\", mte_estimate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
